---
title: "Random images misclassification rate"
output: html_document
---

## Source code

```{r}
source("source.R")
```

## Model

Model: consider a spherical parameter space with radius $R$, $\Omega = B_R(0) \in \mathbb{R}^d$.

Let $P$ be a distribution with density $p(x)$ supported on $\Omega$.

Generate $k$ means, $\mu_i \sim P$. (Each mean belongs to an image.)  Let $\sigma$ be a noise parameter.

Generate $n$ observations per mean, $x_{i, 1},..., x_{i, n} \sim N(\mu_i, \sigma^2 I)$.

From $n_{tr}$ observations per mean estimate $\hat{\mu}_i$ for $i = 1,..., k$.

Then assess the misclassification rate on the remaining $k(n-n_{tr})$ test points.

Set distribution $P$:

```{r}
d <- 20L
b1 <- new("ball", radius = 2, dimension = d)
k <- 10L
centers <- sample_points(b1, k)
covs <- 0.1 * identity_covs(d, k)
wts <- (temp <- runif(k))/sum(temp)
mb1 <- new("mixture_in_ball", domain = b1,
           centers = centers, covariances = covs,
           weights = wts)
de <- density_at(b1, sample_points(mb1, 1e5))
```

Specify simulation parameters:

```{r}
pars <- new("simulation_params",
           prior = b1,
           sigma = 0.1 * diag(rep(1, d)),
           k = 2000L,
           n = 2L,
           n_tr = 1L)
```

Run simulation:
```{r}
sr <- new("simulation_detailed_results", pars)
print(sr)
```

Run multiple simulations:
```{r}
srs <- new("simulation_summary_results", pars, 10L)
print(srs)
```

Theoretical rate
```{r}
theoretical_misc_rate(pars, de)
```

The theoretical rate has very bad worst-case accuracy, but it can be used to find the "change point".

Varying sigmas:

```{r, fig.width=6, fig.height=5}
sigmas <- exp(-(1:20)/2)
mrs <- numeric(length(sigmas))
tmrs_l <- numeric(length(sigmas))
tmrs_u <- numeric(length(sigmas))

for (i in 1:length(sigmas)) {
  pars2 <- pars
  pars2@sigma <- sigmas[i] * diag(rep(1, d))
  mrs[i] <- new("simulation_summary_results", pars2, 10L)@misc_rate
  res <- theoretical_misc_rate(pars2, de)
  tmrs_l[i] <- res$l_rate
  tmrs_u[i] <- res$u_rate
}
plot(-log(sigmas), mrs, type = "o", xlab = "-log sigma", ylab = "misc. rate", ylim = c(0, 1))
lines(-log(sigmas), tmrs_l, col = "red")
lines(-log(sigmas), tmrs_u, col = "red")
title("Empirical misclassification rate (black) vs theoretical (red)")
```

Varying k:

```{r, fig.width=6, fig.height=5}
ks <- 10L * as.integer((1:10)^2)
mrs <- numeric(length(ks))
tmrs_l <- numeric(length(ks))
tmrs_u <- numeric(length(ks))
for (i in 1:length(ks)) {
  pars2 <- pars
  pars2@k <- ks[i]
  mrs[i] <- new("simulation_summary_results", pars2, 10L)@misc_rate
  res <- theoretical_misc_rate(pars2, de)
  tmrs_l[i] <- res$l_rate
  tmrs_u[i] <- res$u_rate
}
plot(ks, mrs, type = "o", xlab = "k", ylab = "misc. rate", ylim= c(0,1))
lines(ks, tmrs_l, col = "red")
lines(ks, tmrs_u, col = "red")
title("Empirical misclassification rate (black) vs theoretical (red)")
```
