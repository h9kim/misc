---
title: "Simulating (Almost) Linear Models"
author: "Charles Zheng"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

## Introduction

Linear model:

$$
y = x_A '\beta + \epsilon
$$
where $x_A$ are active variables,

$$
x_I = x_A' \Gamma + E
$$

where $x_B$ are inactive variables.


Almost-linear model:

$$
y = x_A' \beta_A +\delta f(x_A) + \epsilon
$$

while as before,

$$
x_I = x_A' \Gamma + E
$$

where $f(x_A)$ is a nonlinear perturbation satisfying $\text{E}[f(x_A) x_A] = 0$

In both the linear and almost-linear model, if we define
$$
\beta = \text{E}[x x']^{-1} \text{E}[y x]
$$
then
$$\beta_I = 0$$
and
$$\beta_A = \beta_A$$

### Examples of nonlinear functions

Nadaraya-Watson surface:

Let $u_1, .., u_k$ be control points in the space of active variables $\mathcal{X}_A$,
let $\alpha_1,...,\alpha_k$ be real-valued amplitudes and
let $w_1,..., w_k$ be weights, and $\phi(x)$ the standard multivariate normal density
Then define
$$
\tilde{f}(x) = \frac{\sum_{i=1}^k w_i \alpha_i \phi(x - u_i)}{\sum_{i=1}^k w_i \phi(x - u_i)}
$$
and
$$
f(x) = \tilde{f}(x) - \gamma'x 
$$
where $\gamma$ is defined by
$$
\gamma = \text{E}[x x']^{-1} \text{E}[\tilde{f}(x) x]
$$

### Code Demo

Generate random 2-dimensional design points

```{r}
library(reginference)
x <- randn(100, 2)
u <- randn(3, 2)
w <- rep(1, 3)
a <- rnorm(3)
f <- nw_surface(x, u, a, w)
```

Check that the function has the desired properties

```{r}
y <- f(x)
lm(y ~ x)
```

Visualize

```{r, eval = FALSE}
x2 <- randu(1000, 2, TRUE)
y2 <- f(x2)
library(rgl)
plot3d(cbind(x2, y2))
```

## Inference

### Linear case

Generate design matrix, true beta, and nonlinear perturbation

```{r}
library(reginference)
library(magrittr)
p <- 10
n <- 1000
sigma_y <- 3
bt <- rnorm(p)
x <- randn(n, p, colnames = TRUE)
y0 <- x %*% bt
noise <- sigma_y * rnorm(n)
y <- y0 + noise
```

Generate derived variables
```{r}
x_aug <- noised_projections(x, sigma = 0.1, q = 100, adjoin = TRUE)
colnames(x_aug)[1:20]
```
Marginal screening
```{r}
colnames(x_aug)[order(abs(cor(x_aug, y)), decreasing = TRUE)][1:10]
```

Classical regression
```{r}
res_c <- lm(y ~ x_aug)
pvals <- summary(res_c)$coefficients[, 4][-1]
colnames(x_aug)[order(pvals)][1:10]
```

Knockoff Filter
```{r}
library(knockoff)
res_k <- knockoff.filter(x, y)
res_k$selected
```

### Nonlinear case

```{r, fig.show = 'hold', fig.width=5, fig.height=6}
pt <- random_nw_surface(x, 2, h = 10, handle = FALSE)
delta <- 2
yn <- y0 + delta * pt + (sigma_y - delta) * noise
plot(y0, y0 + delta * pt, pch = '.')
```

Marginal screening
```{r}
colnames(x_aug)[order(abs(cor(x_aug, yn)), decreasing = TRUE)][1:10]
```

Classical regression
```{r}
res_c <- lm(yn ~ x_aug)
pvals <- summary(res_c)$coefficients[, 4][-1]
colnames(x_aug)[order(pvals)][1:10]
```

Knockoff Filter
```{r}
res_k <- knockoff.filter(x, yn)
res_k$selected
```

### Logistic transform case

```{r, fig.show = 'hold', fig.width=5, fig.height=6}
lf <- function(x, delta) { 2/delta * (exp(x * delta) - 1)/(1 + exp(x * delta)) }
delta <- 1
yn <- lf(y0, delta) %>% t %>% t + noise
plot(y0, lf(y0, delta))
```

Marginal screening
```{r}
colnames(x_aug)[order(abs(cor(x_aug, yn)), decreasing = TRUE)][1:10]
```

Classical regression
```{r}
res_c <- lm(yn ~ x_aug)
pvals <- summary(res_c)$coefficients[, 4][-1]
colnames(x_aug)[order(pvals)][1:10]
```

Knockoff Filter
```{r}
res_k <- knockoff.filter(x, yn)
res_k$selected
```